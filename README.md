# Image-Captioning-with-Visual-Attention
The model tackles the task of automatically generating captions for images by focusing on different regions of the image as it generates each word in the caption.
A ResNet model is employed to encode the images, while LSTM cells with an attention mechanism serve as the decoder, generating the captions.

# Model

![image](https://github.com/user-attachments/assets/9c5b190b-fbec-48a9-93e4-3d452747512f)

# results

![image](https://github.com/user-attachments/assets/55c6f16f-2539-4b8f-ba63-2dfb940a08e6)



