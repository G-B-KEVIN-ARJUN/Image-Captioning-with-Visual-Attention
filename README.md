# Image-Captioning-with-Visual-Attention
The model tackles the task of automatically generating captions for images by focusing on different regions of the image as it generates each word in the caption.  A ResNet model is employed to encode the images, while LSTM cells with an attention mechanism serve as the decoder, generating the captions.
